{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42379c4d-a754-424c-b2c7-642151a578c4",
   "metadata": {},
   "source": [
    "# Clean DNN version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6582ca11-14c6-4000-b75d-3b3a65013579",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f5f15e-00c8-456d-9b4a-1bf03097ba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Welcome to JupyROOT 6.28/10\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import ROOT;\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "\n",
    "\n",
    "input_columns = ['DER_deltaeta_jet_jet', 'DER_deltar_tau_lep',\n",
    "'DER_lep_eta_centrality','DER_mass_MMC',\n",
    "'DER_mass_jet_jet', 'DER_mass_transverse_met_lep',\n",
    "'DER_mass_vis', 'DER_met_phi_centrality', \n",
    "'DER_prodeta_jet_jet', 'DER_pt_h', \n",
    "'DER_pt_ratio_lep_tau','DER_pt_tot', \n",
    "'DER_sum_pt','PRI_jet_all_pt',\n",
    "'PRI_jet_leading_eta', 'PRI_jet_leading_phi', \n",
    "'PRI_jet_leading_pt','PRI_jet_num',\n",
    "'PRI_jet_subleading_eta','PRI_jet_subleading_phi', \n",
    " 'PRI_jet_subleading_pt', 'PRI_lep_eta', \n",
    "'PRI_lep_phi', 'PRI_lep_pt', \n",
    "'PRI_met','PRI_met_sumet', \n",
    "'PRI_tau_eta', 'PRI_tau_pt',\n",
    "'transverse_lepton_jet_mass']\n",
    "\n",
    "\n",
    "\n",
    "RDF = ROOT.ROOT.RDataFrame\n",
    "\n",
    "signal_tree_name = 'signal'\n",
    "background_tree_name = 'background'\n",
    "test_tree_name = 'validation'\n",
    "file_name = 'atlas-higgs-challenge-2014-v2_part.root'\n",
    "\n",
    "rdf_signal = RDF(signal_tree_name, file_name)\n",
    "rdf_bkg = RDF(background_tree_name, file_name)\n",
    "rdf_test = RDF(test_tree_name, file_name)\n",
    "\n",
    "reconstruct_transverse_lepton_jet_mass = '''\n",
    "\n",
    "float lep_px = PRI_lep_pt * TMath::Cos(PRI_lep_phi);\n",
    "float lep_py = PRI_lep_pt * TMath::Sin(PRI_lep_phi);\n",
    "float jet_px = PRI_jet_leading_pt * TMath::Cos(PRI_jet_leading_phi);\n",
    "float jet_py = PRI_jet_leading_pt * TMath::Sin(PRI_jet_leading_phi);\n",
    "\n",
    "//calculate angle between jet and lepton\n",
    "float cos_theta = (lep_px*jet_px + lep_py*jet_py) / PRI_lep_pt / PRI_jet_leading_pt;\n",
    "\n",
    "return PRI_lep_pt * PRI_jet_leading_pt * (1 - cos_theta);\n",
    "'''\n",
    "\n",
    "#insertion\n",
    "rdf_signal = rdf_signal.Define('transverse_lepton_jet_mass', reconstruct_transverse_lepton_jet_mass)\n",
    "rdf_bkg = rdf_bkg.Define('transverse_lepton_jet_mass', reconstruct_transverse_lepton_jet_mass)\n",
    "rdf_test = rdf_test.Define('transverse_lepton_jet_mass', reconstruct_transverse_lepton_jet_mass)\n",
    "\n",
    "# label classification to int values\n",
    "rdf_test = rdf_test.Define('IntLabel', '''\n",
    "const char ch = Label[0];\n",
    "const char s = 's';\n",
    "if(ch == s){\n",
    "    return 1;\n",
    "}\n",
    "else{\n",
    "    return 0;\n",
    "}\n",
    "''')\n",
    "\n",
    "\n",
    "df_signal = pd.DataFrame(rdf_signal.AsNumpy())\n",
    "df_bg = pd.DataFrame(rdf_bkg.AsNumpy())\n",
    "df_test = pd.DataFrame(rdf_test.AsNumpy())\n",
    "\n",
    "for tdf in [df_signal, df_bg, df_test]:\n",
    "    tdf['PRI_lep_eta'] = tdf['PRI_lep_eta'].abs()\n",
    "    tdf['PRI_tau_eta'] = tdf['PRI_tau_eta'].abs()\n",
    "\n",
    "\n",
    "\n",
    "#input feature arrays\n",
    "vars_signal = df_signal[input_columns].to_numpy()\n",
    "vars_bg = df_bg[input_columns].to_numpy()\n",
    "vars_test = df_test[input_columns].to_numpy()\n",
    "inputs = np.concatenate([vars_signal, vars_bg])\n",
    "\n",
    "\n",
    "#weights\n",
    "weight_signal = df_signal['Weight'].to_numpy()\n",
    "weight_bg = df_bg['Weight'].to_numpy()\n",
    "weights_test = df_test['Weight'].to_numpy()\n",
    "weights = np.concatenate([weight_signal, weight_bg])\n",
    "weights = weights.reshape((weights.shape[0],))\n",
    "\n",
    "\n",
    "\n",
    "# target classifictionation (1:signal / 0: background)\n",
    "y_signal = np.ones((vars_signal.shape[0], ))\n",
    "y_bg = np.zeros((vars_bg.shape[0], ))\n",
    "y_test = df_test.IntLabel.to_numpy()\n",
    "targets = np.concatenate([y_signal, y_bg])\n",
    "\n",
    "# shuffle \n",
    "inputs, targets, weights = shuffle(inputs, targets, weights)\n",
    "\n",
    "# training and validation split  (80, 20)\n",
    "x_train, x_val, y_train, y_val, w_train, w_val = train_test_split(inputs, targets, weights, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aef7c5-98be-4d13-9510-9cc4063de3ef",
   "metadata": {},
   "source": [
    "## preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca937e4-774e-4765-a41e-e0d3ef31cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler;\n",
    "from imblearn.over_sampling import SMOTE\n",
    " \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train) #set up only on train data\n",
    " \n",
    "# tranformation applied to all\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(vars_test)\n",
    "\n",
    "\n",
    "# inbalance signal - bg\n",
    "smote = SMOTE()\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33192d19-dead-4434-84eb-e9a00dd3ddf7",
   "metadata": {},
   "source": [
    "### AMS and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1d9373-045d-408a-bf89-10f0e118a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ams_score(x, y, w, cut):\n",
    "# Calculate Average Mean Significane as defined in ATLAS paper\n",
    "#    -  approximative formula for large statistics with regularisation\n",
    "# x: array of truth values (1 if signal)\n",
    "# y: array of classifier result\n",
    "# w: array of event weights\n",
    "# cut\n",
    "    t = y > cut \n",
    "    s = np.sum((x[t] == 1)*w[t])\n",
    "    b = np.sum((x[t] == 0)*w[t])\n",
    "    return s/np.sqrt(b+10.0)\n",
    "\n",
    "def find_best_ams_score(x, y, w):\n",
    "# find best value of AMS by scanning cut values; \n",
    "# x: array of truth values (1 if signal)\n",
    "# y: array of classifier results\n",
    "# w: array of event weights\n",
    "#  returns \n",
    "#   ntuple of best value of AMS and the corresponding cut value\n",
    "#   list with corresponding pairs (ams, cut) \n",
    "# ----------------------------------------------------------\n",
    "    ymin=min(y) # classifiers may not be in range [0.,1.]\n",
    "    ymax=max(y)\n",
    "    nprobe=200    # number of (equally spaced) scan points to probe classifier \n",
    "    amsvec= [(ams_score(x, y, w, cut), cut) for cut in np.linspace(ymin, ymax, nprobe)] \n",
    "    maxams=sorted(amsvec, key=lambda lst: lst[0] )[-1]\n",
    "    return maxams, amsvec\n",
    "\n",
    "\n",
    "def printScoreTest(model):\n",
    "    try:\n",
    "        pred_clf = model.predict_proba(x_test)[:, 1]\n",
    "    except:\n",
    "        pred_clf = model.predict(x_test)\n",
    "        pred_clf = pred_clf.reshape((pred_clf.shape[0],))\n",
    "\n",
    "    auc = roc_auc_score(y_test, pred_clf, sample_weight=weights_test)\n",
    "    print('AUC:', auc)\n",
    "    bs = find_best_ams_score(y_test, pred_clf, weights_test)\n",
    "    print('AMS:', bs[0][0])\n",
    "    print('AMS total:', bs[0][0]*np.sqrt(50))\n",
    "\n",
    "\n",
    "def printScore(model):\n",
    "    try:\n",
    "        pred_clf = model.predict_proba(x_val)[:, 1]\n",
    "    except:\n",
    "        pred_clf = model.predict(x_val)\n",
    "        pred_clf = pred_clf.reshape((pred_clf.shape[0],))\n",
    "\n",
    "    auc = roc_auc_score(y_val, pred_clf, sample_weight=w_val)\n",
    "    print('AUC:', auc)\n",
    "    bs = find_best_ams_score(y_val, pred_clf, w_val)\n",
    "    print('AMS:', bs[0][0])\n",
    "    print('AMS total:', bs[0][0]*np.sqrt(50))\n",
    "\n",
    "\n",
    "def plotLossAccuracy(history):\n",
    "    # Get training and validation loss/accuracy values from history\n",
    "    loss_training = history.history['loss']\n",
    "    loss_validation = history.history['val_loss']\n",
    "    accuracy_training = history.history['accuracy']\n",
    "    accuracy_validation = history.history['val_accuracy']\n",
    "\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20, 8))\n",
    "    \n",
    "    ax1.plot(loss_training, '-', label='training')\n",
    "    ax1.plot(loss_validation, '-', label='validation')\n",
    "    ax1.legend(title='loss')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    \n",
    "    ax2.plot(accuracy_training, '-', label='training')\n",
    "    ax2.plot(accuracy_validation, '-', label='validation')\n",
    "    ax2.legend(title='accuracy')\n",
    "    ax2.set_xlabel('epoch')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c20b415-af77-4a36-a8d9-9a7bca6c85d7",
   "metadata": {},
   "source": [
    "### model and training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d25c816-18ac-4d7e-a408-4404a8d0b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training function\n",
    "def train(model, epochs=10, batch_size=128, learning_rate=1e-3, verbose=\"auto\", callbacks=None):\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=learning_rate, weight_decay=0.5),\n",
    "    #    metrics=['accuracy']\n",
    "        metrics=[AUC()]\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        batch_size=batch_size, epochs=epochs,\n",
    "                        verbose=verbose,   callbacks=callbacks)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689912ce-f934-4227-882f-b166984e11d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 21:49:44.326412: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-30 21:49:44.327101: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 21:49:44.330812: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 21:49:44.376467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-30 21:49:45.188828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf;\n",
    "from tensorflow.keras import layers, models, optimizers;\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# Define the DNN model\n",
    "def buildModel():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # input\n",
    "    model.add(layers.Input(shape=(x_train.shape[1],)))\n",
    "    \n",
    "    # hidden\n",
    "    #model.add(layers.Dense(2*128, activation='relu'))\n",
    "    #model.add(layers.Dropout(0.4))\n",
    "    #model.add(layers.Dense(2*128, activation='relu'))\n",
    "    #model.add(layers.Dropout(0.4))    \n",
    "    model.add(layers.Dense(2*128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    #model.add(layers.Dense(128, activation='relu'))\n",
    "    #model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    \n",
    "    \n",
    "    # output\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2783d676-d0d5-4f2c-8338-9d6165847773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m7,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,737</span> (174.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,737\u001b[0m (174.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,737</span> (174.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,737\u001b[0m (174.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - auc: 0.5982 - loss: 0.6777 - val_auc: 0.7790 - val_loss: 0.5881\n",
      "Epoch 2/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.7575 - loss: 0.5961 - val_auc: 0.8186 - val_loss: 0.5296\n",
      "Epoch 3/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.7941 - loss: 0.5543 - val_auc: 0.8334 - val_loss: 0.5079\n",
      "Epoch 4/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - auc: 0.8078 - loss: 0.5385 - val_auc: 0.8446 - val_loss: 0.4967\n",
      "Epoch 5/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8249 - loss: 0.5142 - val_auc: 0.8538 - val_loss: 0.4833\n",
      "Epoch 6/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8337 - loss: 0.5035 - val_auc: 0.8622 - val_loss: 0.4753\n",
      "Epoch 7/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8404 - loss: 0.4939 - val_auc: 0.8683 - val_loss: 0.4635\n",
      "Epoch 8/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8525 - loss: 0.4774 - val_auc: 0.8733 - val_loss: 0.4553\n",
      "Epoch 9/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8566 - loss: 0.4719 - val_auc: 0.8775 - val_loss: 0.4466\n",
      "Epoch 10/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8620 - loss: 0.4635 - val_auc: 0.8809 - val_loss: 0.4334\n",
      "Epoch 11/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - auc: 0.8668 - loss: 0.4566 - val_auc: 0.8834 - val_loss: 0.4317\n",
      "Epoch 12/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8699 - loss: 0.4524 - val_auc: 0.8852 - val_loss: 0.4314\n",
      "Epoch 13/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - auc: 0.8720 - loss: 0.4485 - val_auc: 0.8868 - val_loss: 0.4346\n",
      "Epoch 14/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8760 - loss: 0.4428 - val_auc: 0.8880 - val_loss: 0.4311\n",
      "Epoch 15/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - auc: 0.8793 - loss: 0.4369 - val_auc: 0.8896 - val_loss: 0.4247\n",
      "Epoch 16/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8783 - loss: 0.4388 - val_auc: 0.8908 - val_loss: 0.4213\n",
      "Epoch 17/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8823 - loss: 0.4313 - val_auc: 0.8920 - val_loss: 0.4173\n",
      "Epoch 18/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - auc: 0.8824 - loss: 0.4323 - val_auc: 0.8928 - val_loss: 0.4196\n",
      "Epoch 19/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8888 - loss: 0.4210 - val_auc: 0.8932 - val_loss: 0.4186\n",
      "Epoch 20/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8873 - loss: 0.4232 - val_auc: 0.8936 - val_loss: 0.4147\n",
      "Epoch 21/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8866 - loss: 0.4243 - val_auc: 0.8946 - val_loss: 0.4145\n",
      "Epoch 22/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8908 - loss: 0.4179 - val_auc: 0.8950 - val_loss: 0.4121\n",
      "Epoch 23/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8887 - loss: 0.4212 - val_auc: 0.8960 - val_loss: 0.4081\n",
      "Epoch 24/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8931 - loss: 0.4127 - val_auc: 0.8962 - val_loss: 0.4080\n",
      "Epoch 25/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - auc: 0.8927 - loss: 0.4149 - val_auc: 0.8965 - val_loss: 0.4088\n",
      "Epoch 26/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8926 - loss: 0.4138 - val_auc: 0.8969 - val_loss: 0.4062\n",
      "Epoch 27/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - auc: 0.8943 - loss: 0.4111 - val_auc: 0.8974 - val_loss: 0.4034\n",
      "Epoch 28/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8941 - loss: 0.4112 - val_auc: 0.8972 - val_loss: 0.4049\n",
      "Epoch 29/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8981 - loss: 0.4052 - val_auc: 0.8978 - val_loss: 0.4035\n",
      "Epoch 30/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - auc: 0.8938 - loss: 0.4126 - val_auc: 0.8981 - val_loss: 0.4015\n",
      "Epoch 31/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8968 - loss: 0.4076 - val_auc: 0.8984 - val_loss: 0.4064\n",
      "Epoch 32/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8973 - loss: 0.4055 - val_auc: 0.8989 - val_loss: 0.4043\n",
      "Epoch 33/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8986 - loss: 0.4038 - val_auc: 0.8989 - val_loss: 0.4030\n",
      "Epoch 34/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - auc: 0.8983 - loss: 0.4048 - val_auc: 0.8993 - val_loss: 0.4012\n",
      "Epoch 35/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8989 - loss: 0.4025 - val_auc: 0.8992 - val_loss: 0.4022\n",
      "Epoch 36/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.8982 - loss: 0.4046 - val_auc: 0.8998 - val_loss: 0.3971\n",
      "Epoch 37/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - auc: 0.9014 - loss: 0.3985 - val_auc: 0.8998 - val_loss: 0.4015\n",
      "Epoch 38/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - auc: 0.9035 - loss: 0.3942 - val_auc: 0.8999 - val_loss: 0.4060\n",
      "Epoch 39/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9015 - loss: 0.3971 - val_auc: 0.8998 - val_loss: 0.3981\n",
      "Epoch 40/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9022 - loss: 0.3970 - val_auc: 0.9003 - val_loss: 0.4018\n",
      "Epoch 41/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9024 - loss: 0.3963 - val_auc: 0.9006 - val_loss: 0.4000\n",
      "Epoch 42/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.8994 - loss: 0.4004 - val_auc: 0.9003 - val_loss: 0.3996\n",
      "Epoch 43/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9042 - loss: 0.3923 - val_auc: 0.9008 - val_loss: 0.3981\n",
      "Epoch 44/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9025 - loss: 0.3961 - val_auc: 0.9003 - val_loss: 0.4008\n",
      "Epoch 45/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9034 - loss: 0.3935 - val_auc: 0.9008 - val_loss: 0.3990\n",
      "Epoch 46/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.9047 - loss: 0.3919 - val_auc: 0.9013 - val_loss: 0.3998\n",
      "Epoch 47/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - auc: 0.9013 - loss: 0.3978 - val_auc: 0.9013 - val_loss: 0.3976\n",
      "Epoch 48/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - auc: 0.9045 - loss: 0.3919 - val_auc: 0.9009 - val_loss: 0.3963\n",
      "Epoch 49/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9034 - loss: 0.3936 - val_auc: 0.9021 - val_loss: 0.3961\n",
      "Epoch 50/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.9045 - loss: 0.3921 - val_auc: 0.9019 - val_loss: 0.3947\n",
      "Epoch 51/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9042 - loss: 0.3926 - val_auc: 0.9020 - val_loss: 0.3962\n",
      "Epoch 52/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.9057 - loss: 0.3894 - val_auc: 0.9022 - val_loss: 0.3937\n",
      "Epoch 53/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9040 - loss: 0.3927 - val_auc: 0.9021 - val_loss: 0.3985\n",
      "Epoch 54/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9031 - loss: 0.3948 - val_auc: 0.9023 - val_loss: 0.3968\n",
      "Epoch 55/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9060 - loss: 0.3889 - val_auc: 0.9026 - val_loss: 0.3977\n",
      "Epoch 56/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - auc: 0.9044 - loss: 0.3920 - val_auc: 0.9024 - val_loss: 0.3930\n",
      "Epoch 57/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9037 - loss: 0.3925 - val_auc: 0.9023 - val_loss: 0.3915\n",
      "Epoch 58/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.9078 - loss: 0.3856 - val_auc: 0.9022 - val_loss: 0.3897\n",
      "Epoch 59/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - auc: 0.9054 - loss: 0.3898 - val_auc: 0.9026 - val_loss: 0.3958\n",
      "Epoch 60/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9068 - loss: 0.3866 - val_auc: 0.9024 - val_loss: 0.3965\n",
      "Epoch 61/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - auc: 0.9056 - loss: 0.3892 - val_auc: 0.9027 - val_loss: 0.3914\n",
      "Epoch 62/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9064 - loss: 0.3878 - val_auc: 0.9028 - val_loss: 0.3940\n",
      "Epoch 63/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9085 - loss: 0.3834 - val_auc: 0.9025 - val_loss: 0.3904\n",
      "Epoch 64/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - auc: 0.9087 - loss: 0.3833 - val_auc: 0.9029 - val_loss: 0.3891\n",
      "Epoch 65/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9096 - loss: 0.3814 - val_auc: 0.9032 - val_loss: 0.3933\n",
      "Epoch 66/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9095 - loss: 0.3820 - val_auc: 0.9031 - val_loss: 0.3917\n",
      "Epoch 67/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9087 - loss: 0.3830 - val_auc: 0.9032 - val_loss: 0.3899\n",
      "Epoch 68/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9080 - loss: 0.3840 - val_auc: 0.9032 - val_loss: 0.3922\n",
      "Epoch 69/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.9088 - loss: 0.3831 - val_auc: 0.9036 - val_loss: 0.3889\n",
      "Epoch 70/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9089 - loss: 0.3823 - val_auc: 0.9030 - val_loss: 0.3886\n",
      "Epoch 71/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9093 - loss: 0.3819 - val_auc: 0.9030 - val_loss: 0.3900\n",
      "Epoch 72/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - auc: 0.9092 - loss: 0.3822 - val_auc: 0.9037 - val_loss: 0.3923\n",
      "Epoch 73/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - auc: 0.9113 - loss: 0.3779 - val_auc: 0.9037 - val_loss: 0.3928\n",
      "Epoch 74/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - auc: 0.9097 - loss: 0.3818 - val_auc: 0.9029 - val_loss: 0.3946\n",
      "Epoch 75/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9082 - loss: 0.3843 - val_auc: 0.9037 - val_loss: 0.3936\n",
      "Epoch 76/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9080 - loss: 0.3838 - val_auc: 0.9036 - val_loss: 0.3914\n",
      "Epoch 77/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.9105 - loss: 0.3795 - val_auc: 0.9038 - val_loss: 0.3875\n",
      "Epoch 78/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - auc: 0.9108 - loss: 0.3789 - val_auc: 0.9037 - val_loss: 0.3894\n",
      "Epoch 79/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.9097 - loss: 0.3812 - val_auc: 0.9040 - val_loss: 0.3872\n",
      "Epoch 80/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9094 - loss: 0.3817 - val_auc: 0.9039 - val_loss: 0.3872\n",
      "Epoch 81/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9118 - loss: 0.3767 - val_auc: 0.9038 - val_loss: 0.3900\n",
      "Epoch 82/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - auc: 0.9091 - loss: 0.3819 - val_auc: 0.9035 - val_loss: 0.3867\n",
      "Epoch 83/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9117 - loss: 0.3770 - val_auc: 0.9040 - val_loss: 0.3878\n",
      "Epoch 84/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9091 - loss: 0.3821 - val_auc: 0.9037 - val_loss: 0.3912\n",
      "Epoch 85/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - auc: 0.9117 - loss: 0.3765 - val_auc: 0.9040 - val_loss: 0.3906\n",
      "Epoch 86/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - auc: 0.9108 - loss: 0.3785 - val_auc: 0.9036 - val_loss: 0.3878\n",
      "Epoch 87/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - auc: 0.9114 - loss: 0.3781 - val_auc: 0.9041 - val_loss: 0.3909\n",
      "Epoch 88/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - auc: 0.9095 - loss: 0.3814 - val_auc: 0.9036 - val_loss: 0.3941\n",
      "Epoch 89/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9127 - loss: 0.3742 - val_auc: 0.9038 - val_loss: 0.3906\n",
      "Epoch 90/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - auc: 0.9098 - loss: 0.3802 - val_auc: 0.9037 - val_loss: 0.3888\n",
      "Epoch 91/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9129 - loss: 0.3744 - val_auc: 0.9041 - val_loss: 0.3916\n",
      "Epoch 92/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9131 - loss: 0.3736 - val_auc: 0.9043 - val_loss: 0.3893\n",
      "Epoch 93/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - auc: 0.9110 - loss: 0.3783 - val_auc: 0.9041 - val_loss: 0.3910\n",
      "Epoch 94/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - auc: 0.9119 - loss: 0.3761 - val_auc: 0.9042 - val_loss: 0.3873\n",
      "Epoch 95/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9120 - loss: 0.3763 - val_auc: 0.9041 - val_loss: 0.3911\n",
      "Epoch 96/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9119 - loss: 0.3759 - val_auc: 0.9041 - val_loss: 0.3892\n",
      "Epoch 97/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9133 - loss: 0.3738 - val_auc: 0.9042 - val_loss: 0.3883\n",
      "Epoch 98/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9119 - loss: 0.3766 - val_auc: 0.9040 - val_loss: 0.3887\n",
      "Epoch 99/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9135 - loss: 0.3733 - val_auc: 0.9045 - val_loss: 0.3908\n",
      "Epoch 100/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - auc: 0.9117 - loss: 0.3766 - val_auc: 0.9042 - val_loss: 0.3875\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step\n",
      "AUC: 0.9267777879008706\n",
      "AMS: 0.3690697062972268\n",
      "AMS total: 2.609716920532965\n"
     ]
    }
   ],
   "source": [
    "name = 'v1'\n",
    "\n",
    "model = buildModel()\n",
    "\n",
    "callbacks = [ModelCheckpoint(filepath=f'new/{name}.keras', save_best_only=True), \n",
    "            CSVLogger(f'new/{name}_training.log')\n",
    "          ]\n",
    "        \n",
    "history = train(model, epochs=100, batch_size=2*1024, learning_rate=3e-4, callbacks=callbacks)\n",
    "\n",
    "printScore(model)\n",
    "#plotLossAccuracy(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643de85d-3a14-4c61-a8bc-b58a8e11436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ams_wrapper(prediction, true_values, weights):\n",
    "    return find_best_ams_score(true_values, prediction, weights)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95569bf9-74d8-4770-ad77-c90e49268def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3690697062972268"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(x_val)\n",
    "prediction = prediction.reshape((prediction.shape[0],))\n",
    "\n",
    "ams_wrapper(prediction, y_val, w_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bde74e7-32f2-463c-abe2-1ddcaf0c1038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.743785820496553"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(x_test)\n",
    "prediction = prediction.reshape((prediction.shape[0],))\n",
    "\n",
    "ams_wrapper(prediction, y_test, weights_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
